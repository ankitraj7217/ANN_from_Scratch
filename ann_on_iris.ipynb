{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANN on Iris Dataset with adam optimizer from numpy and pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset fetching\n",
    "dataset = pd.read_csv(\"Iris.csv\")\n",
    "X = dataset.iloc[:,:-1].values\n",
    "y = dataset.iloc[:,4:5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width variety\n",
       "0           5.1          3.5           1.4          0.2  Setosa\n",
       "1           4.9          3.0           1.4          0.2  Setosa\n",
       "2           4.7          3.2           1.3          0.2  Setosa\n",
       "3           4.6          3.1           1.5          0.2  Setosa\n",
       "4           5.0          3.6           1.4          0.2  Setosa"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.1,  3.5,  1.4,  0.2],\n",
       "       [ 4.9,  3. ,  1.4,  0.2],\n",
       "       [ 4.7,  3.2,  1.3,  0.2],\n",
       "       [ 4.6,  3.1,  1.5,  0.2],\n",
       "       [ 5. ,  3.6,  1.4,  0.2]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Setosa'],\n",
       "       ['Setosa'],\n",
       "       ['Setosa'],\n",
       "       ['Setosa'],\n",
       "       ['Setosa']], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AR\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#sklearn is used only for data preprocessing\n",
    "#Changing to onehotencoder\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "label_enc_obj = LabelEncoder()\n",
    "y = label_enc_obj.fit_transform(y)\n",
    "y = y.reshape(150,1)\n",
    "onehot_enc_obj = OneHotEncoder(categorical_features=[0])\n",
    "y = onehot_enc_obj.fit_transform(y).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AR\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Train-Test Split\n",
    "#sklearn is used only for data preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-train [[ 5.9  3.2  4.8  1.8]\n",
      " [ 4.6  3.1  1.5  0.2]\n",
      " [ 4.4  3.2  1.3  0.2]\n",
      " [ 5.6  3.   4.1  1.3]\n",
      " [ 5.2  4.1  1.5  0.1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"X-train\",X_train[:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.17532237,  0.02980188,  0.60885268,  0.35610778],\n",
       "       [-0.11003432, -0.92385828,  0.72005865,  0.86941629],\n",
       "       [ 0.94162116, -1.40068836,  1.10927953,  0.74108916],\n",
       "       [ 0.35736811, -0.68544324,  0.55324969,  0.74108916],\n",
       "       [-1.04483919,  1.22187708, -1.33725177, -1.31214488]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:5,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters Initialization\n",
    "class Layer_Utils:\n",
    "    \n",
    "    def __init__(self,input_shape,n_layers,layers_dims,output_shape):\n",
    "        self.input_shape = input_shape\n",
    "        self.n_layers = n_layers\n",
    "        self.layers_dims = layers_dims\n",
    "        self.output_shape = output_shape\n",
    "        \n",
    "    \n",
    "    #Create layer_dims array\n",
    "    def input_layers(self):\n",
    "        \n",
    "        self.layers_dims = [self.input_shape[1]]+self.layers_dims\n",
    "        self.layers_dims.append(self.output_shape[1])\n",
    "            \n",
    "        return self.layers_dims\n",
    "    \n",
    "    #Parameter Initialization\n",
    "    def initialization(self):\n",
    "        parameters = {}\n",
    "        v ={}\n",
    "        s = {}\n",
    "        for i in range(1,self.n_layers+2):\n",
    "            parameters[\"W\"+str(i)] = np.random.randn(self.layers_dims[i-1],self.layers_dims[i])*np.sqrt(1/(self.layers_dims[i-1]+self.layers_dims[i]))\n",
    "            parameters[\"b\"+str(i)] = np.zeros((1,self.layers_dims[i]))\n",
    "            \n",
    "            v[\"dw\"+str(i)] = np.zeros((self.layers_dims[i-1],self.layers_dims[i]))\n",
    "            v[\"db\"+str(i)] = np.zeros((1,self.layers_dims[i]))\n",
    "            \n",
    "            s[\"dw\"+str(i)] = np.zeros((self.layers_dims[i-1],self.layers_dims[i]))\n",
    "            s[\"db\"+str(i)] = np.zeros((1,self.layers_dims[i]))\n",
    "            \n",
    "        return v,s,parameters\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANN Model \n",
    "\n",
    "class ANN:\n",
    "    \n",
    "    def __init__(self,n_layers):\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "    \n",
    "    def relu(self,z):\n",
    "        return np.maximum(0,z)\n",
    "    \n",
    "    def softmax(self,z):\n",
    "        return np.exp(z)/np.sum(np.exp(z),axis=1)[:,np.newaxis]\n",
    "    \n",
    "    def relu_derivative(self,z):\n",
    "        return z > 0  \n",
    "    \n",
    "    \n",
    "    def fp_one_layer(self,X,W,b,activation=True):\n",
    "        \n",
    "        z = np.dot(X,W)+b\n",
    "        a = self.relu(z)\n",
    "        \n",
    "        if activation==False:\n",
    "            return z,z\n",
    "        \n",
    "        return a,z\n",
    "    \n",
    "    def forward_prop(self,X_input,parameters,n_layers):\n",
    "        \n",
    "        a = X_input\n",
    "        activations = {}\n",
    "        forward_z = {}\n",
    "        activations[\"a0\"] = a\n",
    "        forward_z[\"z0\"] = a\n",
    "        \n",
    "        for i in range(1,n_layers+1):\n",
    "            a,z = self.fp_one_layer(a,parameters[\"W\"+str(i)],parameters[\"b\"+str(i)],activation=True)\n",
    "            activations[\"a\"+str(i)] = a\n",
    "            forward_z[\"z\"+str(i)] = z\n",
    "        \n",
    "        z,a = self.fp_one_layer(a,parameters[\"W\"+str(n_layers+1)],parameters[\"b\"+str(n_layers+1)],activation=False)\n",
    "        y_pred = self.softmax(z)      \n",
    "        \n",
    "        return forward_z,activations,z,y_pred\n",
    "\n",
    "    \n",
    "    \n",
    "    def loss(self,y,y_pred):\n",
    "        \n",
    "        m = X_train.shape[0]\n",
    "        categorical_entropy_loss = (1/m)*np.sum(np.multiply(-y,np.log(y_pred)))\n",
    "        \n",
    "        return categorical_entropy_loss\n",
    "            \n",
    "    \n",
    "    #Calculating dl/dz \n",
    "    def loss_der_wrt_z(self,y,y_pred):\n",
    "        return y_pred-y\n",
    "\n",
    "    \n",
    "    def backprop_one_step(self,dz,z,a,w,b):\n",
    "        \n",
    "        m = a.shape[0]\n",
    "        da = np.dot(dz,w.T)\n",
    "        dw = np.dot(a.T,dz)\n",
    "        db = (1/m)*np.sum(dz,axis=0)\n",
    "        z_der = np.multiply(da,self.relu_derivative(z))\n",
    "        \n",
    "        return z_der,dw,db\n",
    "    \n",
    "    \n",
    "    def update_parameters_adam(self,dz,parameters,forward_z,activations,t,v,s,beta1=0.9,beta2=0.99,learning_rate=0.01,epsilon=1e-8):\n",
    "        \n",
    "        for i in range(n_layers+1,0,-1):\n",
    "            dz,dw,db = self.backprop_one_step(dz,forward_z[\"z\"+str(i-1)],activations[\"a\"+str(i-1)],parameters[\"W\"+str(i)],parameters[\"b\"+str(i)])\n",
    "            \n",
    "            v[\"dw\"+str(i)] = (beta1*v[\"dw\"+str(i)])+(1-beta1)*dw\n",
    "            v[\"db\"+str(i)] = (beta1*v[\"db\"+str(i)])+(1-beta1)*db\n",
    "            v_corrected_w = v[\"dw\"+str(i)]/(1-np.power(beta1,t))\n",
    "            v_corrected_b = v[\"db\"+str(i)]/(1-np.power(beta1,t))\n",
    "            \n",
    "            s[\"dw\"+str(i)] = (beta2*s[\"dw\"+str(i)])+(1-beta2)*np.square(dw)\n",
    "            s[\"db\"+str(i)] = (beta2*s[\"db\"+str(i)])+(1-beta2)*np.square(db)\n",
    "            s_corrected_w = s[\"dw\"+str(i)]/(1-np.power(beta2,t))\n",
    "            s_corrected_b = s[\"db\"+str(i)]/(1-np.power(beta2,t))\n",
    "            \n",
    "            parameters[\"W\"+str(i)] = parameters[\"W\"+str(i)]-( learning_rate* ( v_corrected_w/np.sqrt(s_corrected_w+epsilon) ) )\n",
    "            parameters[\"b\"+str(i)] = parameters[\"b\"+str(i)]-( learning_rate* ( v_corrected_b/np.sqrt(s_corrected_b+epsilon) ) )\n",
    "            \n",
    "        \n",
    "        return parameters\n",
    "        \n",
    "        \n",
    "        \n",
    "    def model(self,X_train,y_train,parameters,v,s,n_epochs = 1000):\n",
    "        \n",
    "        for i in range(1,n_epochs+1):\n",
    "            forward_z,activations,z,y_pred = self.forward_prop(X_train,parameters,self.n_layers)\n",
    "            total_loss = self.loss(y_train,y_pred)\n",
    "            print(\"Loss in epoch \" + str(i) + \"=\" +str(total_loss))\n",
    "            dz = self.loss_der_wrt_z(y_train,y_pred)\n",
    "            parameters = self.update_parameters_adam(dz,parameters,forward_z,activations,i,v,s)\n",
    "            \n",
    "        return parameters\n",
    "    \n",
    "    \n",
    "    def prediction(self,parameters,X_test):\n",
    "        _,_,_,a = self.forward_prop(X_test,parameters,self.n_layers)\n",
    "        b = np.zeros_like(a)\n",
    "        b[np.arange(len(a)), a.argmax(1)] = 1\n",
    "        \n",
    "        return b\n",
    "    \n",
    "    def check_accuracy(self,y,y_pred):\n",
    "        m = y.shape[0]\n",
    "        temp = np.equal(y,y_pred)\n",
    "        temp = np.sum(temp,axis=1)\n",
    "        sum = np.count_nonzero(temp==3)\n",
    "        \n",
    "        probab = sum/m\n",
    "        \n",
    "        return probab*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Number of Layers:->3\n",
      "Enter number of neurons in 1:->10\n",
      "Enter number of neurons in 2:->12\n",
      "Enter number of neurons in 3:->10\n"
     ]
    }
   ],
   "source": [
    "#Taking Input from users regarding number of layers and layer_dims\n",
    "\n",
    "n_layers = int(input(\"Enter Number of Layers:->\"))\n",
    "layer_dims = []\n",
    "for i in range(0,n_layers):\n",
    "    layer_dims.append(int(input(\"Enter number of neurons in \" + str(i+1) + \":->\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing parameters by making object of Layer_util_Class\n",
    "\n",
    "layer_util_obj = Layer_Utils(X_train.shape,n_layers,layer_dims,y_train.shape)\n",
    "layer_dims = layer_util_obj.input_layers()\n",
    "v,s,parameters = layer_util_obj.initialization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch 1=1.0836151613\n",
      "Loss in epoch 2=1.06170508091\n",
      "Loss in epoch 3=1.04048750273\n",
      "Loss in epoch 4=1.01801473018\n",
      "Loss in epoch 5=0.993269370213\n",
      "Loss in epoch 6=0.964894893719\n",
      "Loss in epoch 7=0.932700765753\n",
      "Loss in epoch 8=0.897008549699\n",
      "Loss in epoch 9=0.858096347009\n",
      "Loss in epoch 10=0.816791125014\n",
      "Loss in epoch 11=0.773404338563\n",
      "Loss in epoch 12=0.728918979994\n",
      "Loss in epoch 13=0.684087468799\n",
      "Loss in epoch 14=0.640429018097\n",
      "Loss in epoch 15=0.598976590997\n",
      "Loss in epoch 16=0.560547820046\n",
      "Loss in epoch 17=0.525851164909\n",
      "Loss in epoch 18=0.495145179488\n",
      "Loss in epoch 19=0.468759682646\n",
      "Loss in epoch 20=0.44694477637\n",
      "Loss in epoch 21=0.429322443393\n",
      "Loss in epoch 22=0.413956621363\n",
      "Loss in epoch 23=0.39930676441\n",
      "Loss in epoch 24=0.384257292662\n",
      "Loss in epoch 25=0.369249713977\n",
      "Loss in epoch 26=0.355513029467\n",
      "Loss in epoch 27=0.34390256035\n",
      "Loss in epoch 28=0.333910158688\n",
      "Loss in epoch 29=0.324692640644\n",
      "Loss in epoch 30=0.315752962172\n",
      "Loss in epoch 31=0.30818547573\n",
      "Loss in epoch 32=0.302190137892\n",
      "Loss in epoch 33=0.296150865514\n",
      "Loss in epoch 34=0.288874993397\n",
      "Loss in epoch 35=0.280730070476\n",
      "Loss in epoch 36=0.272431943708\n",
      "Loss in epoch 37=0.263866912132\n",
      "Loss in epoch 38=0.254443513152\n",
      "Loss in epoch 39=0.244592795767\n",
      "Loss in epoch 40=0.234942362922\n",
      "Loss in epoch 41=0.225681693132\n",
      "Loss in epoch 42=0.215923928832\n",
      "Loss in epoch 43=0.205415615225\n",
      "Loss in epoch 44=0.194637750972\n",
      "Loss in epoch 45=0.183985001687\n",
      "Loss in epoch 46=0.172379425325\n",
      "Loss in epoch 47=0.160341196246\n",
      "Loss in epoch 48=0.148511762364\n",
      "Loss in epoch 49=0.136593490281\n",
      "Loss in epoch 50=0.12460426958\n",
      "Loss in epoch 51=0.112793825853\n",
      "Loss in epoch 52=0.102099287551\n",
      "Loss in epoch 53=0.0923776785751\n",
      "Loss in epoch 54=0.0843721679209\n",
      "Loss in epoch 55=0.0773786181445\n",
      "Loss in epoch 56=0.0716595377326\n",
      "Loss in epoch 57=0.0670895057696\n",
      "Loss in epoch 58=0.0635984946755\n",
      "Loss in epoch 59=0.0606567643618\n",
      "Loss in epoch 60=0.05806150093\n",
      "Loss in epoch 61=0.0558594138564\n",
      "Loss in epoch 62=0.0539129274044\n",
      "Loss in epoch 63=0.0520795351027\n",
      "Loss in epoch 64=0.0505615793878\n",
      "Loss in epoch 65=0.0494023252939\n",
      "Loss in epoch 66=0.0485001840472\n",
      "Loss in epoch 67=0.0477389408304\n",
      "Loss in epoch 68=0.0471542124415\n",
      "Loss in epoch 69=0.0465175052483\n",
      "Loss in epoch 70=0.0458275129193\n",
      "Loss in epoch 71=0.0451709820226\n",
      "Loss in epoch 72=0.0444367710399\n",
      "Loss in epoch 73=0.0436996275935\n",
      "Loss in epoch 74=0.0430725384538\n",
      "Loss in epoch 75=0.042488757875\n",
      "Loss in epoch 76=0.042032731078\n",
      "Loss in epoch 77=0.041728601325\n",
      "Loss in epoch 78=0.0414426465913\n",
      "Loss in epoch 79=0.0411705967118\n",
      "Loss in epoch 80=0.0409286849257\n",
      "Loss in epoch 81=0.0406489965554\n",
      "Loss in epoch 82=0.040368742972\n",
      "Loss in epoch 83=0.0401079214864\n",
      "Loss in epoch 84=0.0398610680122\n",
      "Loss in epoch 85=0.039630431473\n",
      "Loss in epoch 86=0.0393741222676\n",
      "Loss in epoch 87=0.0391026926772\n",
      "Loss in epoch 88=0.0389402289198\n",
      "Loss in epoch 89=0.0388737272004\n",
      "Loss in epoch 90=0.038806330045\n",
      "Loss in epoch 91=0.0387300137802\n",
      "Loss in epoch 92=0.0386398253352\n",
      "Loss in epoch 93=0.0385554208876\n",
      "Loss in epoch 94=0.0384741347201\n",
      "Loss in epoch 95=0.0384054028347\n",
      "Loss in epoch 96=0.0383526009228\n",
      "Loss in epoch 97=0.038304817066\n",
      "Loss in epoch 98=0.0382832113246\n",
      "Loss in epoch 99=0.0382546329321\n",
      "Loss in epoch 100=0.0382032608064\n"
     ]
    }
   ],
   "source": [
    "#Making object of ANN model\n",
    "\n",
    "ann = ANN(n_layers)\n",
    "parameters = ann.model(X_train,y_train,parameters,v,s,100)\n",
    "y_pred = ann.prediction(parameters,X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for test set is:->  93.33333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for test set is:-> \",ann.check_accuracy(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
